{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arsalan Shoaib Patel - Lab 2\n",
    "## 8865064"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A\n",
    "* Preprocessing\n",
    "* Load the dataset\n",
    "* Use the CountVectorizer function in sklearn to transform the \"text\" feature to a vector representation of a predetermined size.\n",
    "* Split the dataset into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab2 = pd.read_csv(\"Lab2_dataset.csv\")\n",
    "\n",
    "x = df_lab2['text']\n",
    "y = df_lab2['label_num']  # taking label_num as the label\n",
    "\n",
    "# text feature to a vector form\n",
    "x = CountVectorizer() .fit_transform(x)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       752\n",
      "           1       0.90      0.96      0.93       283\n",
      "\n",
      "    accuracy                           0.96      1035\n",
      "   macro avg       0.94      0.96      0.95      1035\n",
      "weighted avg       0.96      0.96      0.96      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ModelSVC = SVC().fit(X_train,y_train)\n",
    "\n",
    "yPredSVC= ModelSVC.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, yPredSVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       752\n",
      "           1       0.93      0.91      0.92       283\n",
      "\n",
      "    accuracy                           0.96      1035\n",
      "   macro avg       0.95      0.94      0.94      1035\n",
      "weighted avg       0.96      0.96      0.96      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# doing to array to make it a dense array\n",
    "ModelGaussian = GaussianNB().fit(X_train.toarray(), y_train)\n",
    "\n",
    "yPredGaussian = ModelGaussian.predict(X_test.toarray())\n",
    "\n",
    "print(classification_report(y_test, yPredGaussian))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       752\n",
      "           1       0.94      0.97      0.95       283\n",
      "\n",
      "    accuracy                           0.97      1035\n",
      "   macro avg       0.96      0.97      0.97      1035\n",
      "weighted avg       0.97      0.97      0.97      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ModelMultimonial = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "yPredMultimonial = ModelMultimonial.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, yPredMultimonial))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Multinomial model had a better performance than the Gaussian and SVC models as its accuracy was greater than them.\n",
    "* The reason for it is that there are different assumptions made about the data by every model as SVC doesn't make distributional assumptions, MNB assumes multinomial distribution and GNB assumes Gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B\n",
    "\n",
    "* Remove outliers based on price per night for a given apartment/home.\n",
    "* Compare the Z-score approach and the whiskers approach in terms of who is better to remove the outliers in this case.\n",
    "* The task is to come up with a clean dataset that does not have outliers showcasing all the possibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zscore approach\n",
    "df_nyc = pd.read_csv(\"AB_NYC_2019.csv\")\n",
    "z_score = stats.zscore(df_nyc['price']) \n",
    "\n",
    "# assuming that the standard z score should be between 3 and -3\n",
    "upper_outlier_Z = (z_score) <= 3\n",
    "lower_outlier_Z = (z_score) >= -3\n",
    "combined_filter = lower_outlier_Z & upper_outlier_Z\n",
    "df_zScore= df_nyc[combined_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#whisker approach\n",
    "Q1 = df_nyc['price'].quantile(0.25)\n",
    "Q3 = df_nyc['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_whisker = df_nyc['price'] >= Q1 - (1.5 * IQR)\n",
    "upper_whisker = df_nyc['price'] <= Q3 + (1.5 * IQR)\n",
    "combined_filter = lower_whisker & upper_whisker\n",
    "df_whisker = df_nyc[combined_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Z Score :\n",
      " count    48507.000000\n",
      "mean       138.746903\n",
      "std        107.558233\n",
      "min          0.000000\n",
      "25%         69.000000\n",
      "50%        105.000000\n",
      "75%        175.000000\n",
      "max        860.000000\n",
      "Name: price, dtype: float64 \n",
      "\n",
      "Summary of Whisker:\n",
      " count    45923.000000\n",
      "mean       119.970320\n",
      "std         68.150148\n",
      "min          0.000000\n",
      "25%         65.000000\n",
      "50%        100.000000\n",
      "75%        159.000000\n",
      "max        334.000000\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary of Z Score :\\n\", df_zScore['price'].describe(),'\\n')\n",
    "print(\"Summary of Whisker:\\n\", df_whisker['price'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The standard deviation of Z score is more than whisker meaning that the data is more spread out.\n",
    "* The prices are narrowed down in the whiskers approach compared to the z score approach as all the quartiles of z score are higher than whisker's. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
